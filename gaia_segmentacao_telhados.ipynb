{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8230b97a",
   "metadata": {},
   "source": [
    "# GAIA-Coleta360 - Segmenta√ß√£o de Telhados\n",
    "Este notebook demonstra como treinar e testar um modelo de segmenta√ß√£o de telhados em imagens de sat√©lite, utilizando PyTorch e FPN com ResNet34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4359e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Instala√ß√£o de depend√™ncias (caso necess√°rio)\n",
    "# !pip install torch torchvision segmentation-models-pytorch albumentations opencv-python matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da4173",
   "metadata": {},
   "source": [
    "## üîß Utils (Dataset, Augmenta√ß√µes, Dice Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class RoofDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, augmentation=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.augmentation = augmentation\n",
    "        self.image_names = sorted(os.listdir(images_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.images_dir, self.image_names[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.image_names[idx])\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.augmentation:\n",
    "            augmented = self.augmentation(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "def get_training_augmentation(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.RandomCrop(height=img_size, width=img_size, p=1.0),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def get_validation_augmentation(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def dice_score(preds, targets, smooth=1e-6):\n",
    "    preds = preds.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    intersection = (preds * targets).sum()\n",
    "    return (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7a6e4",
   "metadata": {},
   "source": [
    "## üöÄ Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from utils import RoofDataset, get_training_augmentation, get_validation_augmentation, dice_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Diret√≥rios\n",
    "DATA_DIR = 'data/train'\n",
    "MASK_DIR = 'data/train_masks'\n",
    "MODEL_DIR = 'models'\n",
    "\n",
    "# Hiperpar√¢metros\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Dataset e DataLoader\n",
    "train_dataset = RoofDataset(\n",
    "    images_dir=DATA_DIR,\n",
    "    masks_dir=MASK_DIR,\n",
    "    augmentation=get_training_augmentation(IMG_SIZE)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Modelo\n",
    "model = smp.FPN(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Otimizador e fun√ß√£o de perda\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Treinamento\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for images, masks in loop:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).unsqueeze(1)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Salvando o modelo\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'fpn_resnet34.pth'))\n",
    "print(\"\\nModelo salvo com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b84b22",
   "metadata": {},
   "source": [
    "## üîç Infer√™ncia e Avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88411aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from utils import RoofDataset, get_validation_augmentation, dice_score\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Diret√≥rios\n",
    "IMAGE_DIR = 'data/test'\n",
    "MASK_DIR = 'data/test_masks'\n",
    "MODEL_PATH = 'models/fpn_resnet34.pth'\n",
    "RESULTS_DIR = 'results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Par√¢metros\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Dataset e DataLoader\n",
    "test_dataset = RoofDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASK_DIR,\n",
    "    augmentation=get_validation_augmentation(IMG_SIZE)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Modelo\n",
    "model = smp.FPN(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Avalia√ß√£o e salvamento\n",
    "all_dice_scores = []\n",
    "with torch.no_grad():\n",
    "    for i, (images, masks) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "\n",
    "        # Dice score\n",
    "        dice = dice_score(preds.float(), masks.float())\n",
    "        all_dice_scores.append(dice.item())\n",
    "\n",
    "        # Salvando resultados\n",
    "        for j in range(images.size(0)):\n",
    "            result_path = os.path.join(RESULTS_DIR, f'result_{i*BATCH_SIZE + j}.png')\n",
    "            save_image(preds[j].float(), result_path)\n",
    "\n",
    "# Resultado final\n",
    "mean_dice = np.mean(all_dice_scores)\n",
    "print(f\"\\nDice Score m√©dio no conjunto de teste: {mean_dice:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
